{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Using Electrodermal Activity to Detect Deception and Suspicion during a Card Game\n",
    "# Affective Computing - Mini-project\n",
    "# Jan Ondras\n",
    "# Dec 2017 - Jan 2018\n",
    "######################################################################################\n",
    "#######################################################################\n",
    "# Generate feature files with filenames of format: \n",
    "# features_{feature_type}_u_{epoch_delay}_{max_epoch_len}.csv\n",
    "# u means unit normalization\n",
    "#######################################################################\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# File\n",
    "def extract_features(feature_type, epoch_delay, max_deception_epoch_length, mean_susp_length, file_ID):\n",
    "\n",
    "    fs = 32. # Hz - sampling frequency\n",
    "    fc = 3.  # Hz - cutoff frequency\n",
    "\n",
    "    norm_type = 1\n",
    "\n",
    "    if norm_type == 0:\n",
    "        norm_to_baseline = True\n",
    "        znormalize = False\n",
    "        unitnormalize = False\n",
    "    elif norm_type == 1:\n",
    "        norm_to_baseline = False\n",
    "        znormalize = False\n",
    "        unitnormalize = True\n",
    "    else:\n",
    "        norm_to_baseline = False\n",
    "        znormalize = True\n",
    "        unitnormalize = False\n",
    "\n",
    "    apply_filter = True #False\n",
    "\n",
    "    # If maximum suspicion epoch length is not provided, use (subject-dependent) estimates from stats of suspicion epoch lengths\n",
    "    # this is not used => go to else\n",
    "    if mean_susp_length == None:\n",
    "        mean_susp_len = {'11': 1.5483870967741935, '10': 1.5, '13': 1.4047619047619047, '12': 1.6428571428571428, '15': 1.6666666666666667, '07': 1.8023255813953489, '17': 1.5714285714285714, '16': 1.1666666666666667, '19': 1.0, '18': 2.0, '08': 1.2592592592592593, '09': 2.25, '04': 2.0, '20': 2.0, '02': 3.0, '01': 3.0, '06': 2.7000000000000002, '05': 1.7142857142857142, '03': 2.2083333333333335, '14': 1.3333333333333333}\n",
    "    else: # same for all\n",
    "        mean_susp_len = {}\n",
    "        for i in range(1, 21):\n",
    "            mean_susp_len['{:02d}'.format(i)] = mean_susp_length\n",
    "        \n",
    "    # Normalize and filter whole EDA recording\n",
    "    # def normalize_and_filter(y, baseline):\n",
    "    #     #y = (y - y.mean()) / y.std() # z-score\n",
    "    #     y = (y - baseline) / (max(y) - baseline) # [0,1]\n",
    "    #     # For digital filters, Wn is normalized from 0 to 1, where 1 is the Nyquist frequency, pi radians/sample\n",
    "    #     b, a = butter(N=32, Wn=2*fc/fs, btype='low', analog=False, output='ba')\n",
    "    #     z = filtfilt(b, a, y)\n",
    "    #     return z\n",
    "\n",
    "    # Normalize EDA recording to the baseline of corresponding subject\n",
    "    # def normalize_to_baseline(y, baseline):\n",
    "    #     return (y - baseline) / (max(y) - baseline) \n",
    "\n",
    "    # Filter whole EDA recording\n",
    "    def filt(y):\n",
    "        # For digital filters, Wn is normalized from 0 to 1, where 1 is the Nyquist frequency, pi radians/sample\n",
    "        b, a = butter(N=5, Wn=2*fc/fs, btype='low', analog=False, output='ba')\n",
    "        z = filtfilt(b, a, y)\n",
    "        return z\n",
    "\n",
    "    # Z-norm EDA signal for a given epoch only\n",
    "    def znorm(y):\n",
    "        return (y - np.mean(y)) / np.std(y) # z-score\n",
    "\n",
    "    # Normalize EDA signal to [0,1] for a given epoch only\n",
    "    def unitnorm(y):\n",
    "        return (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "    # First return value tells whether to keep the sample\n",
    "    def extract_features(data):\n",
    "    #     print data\n",
    "        if len(data) < 2:\n",
    "            return False, []\n",
    "\n",
    "        features = []\n",
    "\n",
    "        # 1.) mean\n",
    "        features.append(np.mean(data))\n",
    "\n",
    "        # 2.) std\n",
    "        std = np.std(data)\n",
    "        features.append(std)\n",
    "        if std == 0.:\n",
    "            return False, []\n",
    "\n",
    "        mafd = np.mean(np.abs(np.diff(data))) # mean absolute first differences, of the raw signal\n",
    "        masd = np.mean(np.abs(np.subtract(data[2:], data[:-2]))) # mean absolute second differences, of the raw signal\n",
    "        if np.isnan(mafd) or np.isnan(masd):\n",
    "            return False, []\n",
    "        else:\n",
    "            mafdN = mafd / std  # mean absolute first differences, of the normalized signal\n",
    "            masdN = masd / std  # mean absolute second differences, of the normalized signal  \n",
    "\n",
    "        features.extend([mafd, mafdN, masd, masdN])\n",
    "\n",
    "        return True, features\n",
    "\n",
    "    # Delay epoch by a fixed amount at both endpoints\n",
    "    def delay_epoch(epoch_start, epoch_end, delay, SID):\n",
    "        # Input and output times are strings \n",
    "        # [:-3] removes microseconds\n",
    "        dt_epoch_start = datetime.strptime(epoch_start, '%H:%M:%S.%f') # datetime object\n",
    "        dt_epoch_end = datetime.strptime(epoch_end, '%H:%M:%S.%f') \n",
    "        # Shorten epochs longer than max_deception_epoch_length (comparing datetime objects)\n",
    "        if dt_epoch_start < dt_epoch_end - timedelta(seconds=max_deception_epoch_length):\n",
    "            dt_epoch_start = dt_epoch_end - timedelta(seconds=max_deception_epoch_length)\n",
    "        # Delay both endpoints\n",
    "        delayed_epoch_start = datetime.strftime(dt_epoch_start + timedelta(seconds=delay), '%H:%M:%S.%f')[:-3]\n",
    "        delayed_epoch_end = datetime.strftime(dt_epoch_end + timedelta(seconds=delay), '%H:%M:%S.%f')[:-3]\n",
    "        return delayed_epoch_start, delayed_epoch_end\n",
    "\n",
    "    # Delay and threshold according to subject-specific mean suspicion epoch length\n",
    "    def delay_susp_epoch(epoch_start, epoch_end, delay, SID):\n",
    "        dt_epoch_start = datetime.strptime(epoch_start, '%H:%M:%S.%f') # datetime object\n",
    "        dt_epoch_end = datetime.strptime(epoch_end, '%H:%M:%S.%f') \n",
    "        # Shorten epochs longer than subject-specific mean suspicion epoch length (mean_susp_len)\n",
    "        if dt_epoch_start < dt_epoch_end - timedelta(seconds=mean_susp_len[SID]):\n",
    "            dt_epoch_start = dt_epoch_end - timedelta(seconds=mean_susp_len[SID])\n",
    "        # Delay both endpoints\n",
    "        delayed_epoch_start = datetime.strftime(dt_epoch_start + timedelta(seconds=delay), '%H:%M:%S.%f')[:-3]\n",
    "        delayed_epoch_end = datetime.strftime(dt_epoch_end + timedelta(seconds=delay), '%H:%M:%S.%f')[:-3]\n",
    "        return delayed_epoch_start, delayed_epoch_end\n",
    "\n",
    "    # Delay and threshold according to subject-specific mean suspicion epoch length\n",
    "    def delay_trust_epoch(epoch_start, epoch_end, delay, SID):\n",
    "        dt_epoch_start = datetime.strptime(epoch_start, '%H:%M:%S.%f') # datetime object\n",
    "        dt_epoch_end = datetime.strptime(epoch_end, '%H:%M:%S.%f') \n",
    "        # Time interval when suspicion/trust happens is from epoch_start \n",
    "        # and it has length mean_susp_len[SID] if epoch_start + 2*mean_susp_len[SID] < epoch_end\n",
    "        # otherwise (epoch_end - epoch_start) / 2\n",
    "#         if dt_epoch_start + timedelta(seconds=mean_susp_len[SID]) < dt_epoch_end:\n",
    "        if dt_epoch_start + timedelta(seconds=2.*mean_susp_len[SID]) < dt_epoch_end:\n",
    "            dt_epoch_end = dt_epoch_start + timedelta(seconds=mean_susp_len[SID])\n",
    "        else:\n",
    "            dt_epoch_end = dt_epoch_start + timedelta(seconds=0.5*(dt_epoch_end-dt_epoch_start).total_seconds())        \n",
    "        # Delay both endpoints\n",
    "        delayed_epoch_start = datetime.strftime(dt_epoch_start + timedelta(seconds=delay), '%H:%M:%S.%f')[:-3]\n",
    "        delayed_epoch_end = datetime.strftime(dt_epoch_end + timedelta(seconds=delay), '%H:%M:%S.%f')[:-3]\n",
    "        return delayed_epoch_start, delayed_epoch_end\n",
    "\n",
    "    deception_classes = ['deception', 'truth'] # 0 = deception, 1 = truth\n",
    "    suspicion_classes = ['suspicion', 'trust'] # 0 = suspicion, 1 = trust\n",
    "\n",
    "    features_deception = []\n",
    "    features_suspicion = []\n",
    "\n",
    "    numS = 0\n",
    "\n",
    "    # Load EDA baseline epochs for each subject \n",
    "    # Structure of EDA baseline epochs file: \n",
    "    # Subject ID | Baseline epoch start (system) time | Baseline epoch end (system) time \n",
    "    # baselines = np.loadtxt('./../Experiment/EDA/BaselineEDA.csv', delimiter=\",\", skiprows=1, dtype=str)\n",
    "    # baseline_epochs = dict(zip(baselines[:, 0], baselines[:, 1:]))\n",
    "    # print \"Baselines: \\n\", baseline_epochs\n",
    "\n",
    "    # Iterate over games (10 in total)\n",
    "    game_events_files = glob.glob('./../Experiment/AnnotatedEvents/G*.csv')\n",
    "    for game_events_file_name in game_events_files:\n",
    "\n",
    "        # Extract subject IDs of players\n",
    "        P1_SID = game_events_file_name[-8:-6]\n",
    "        P2_SID = game_events_file_name[-6:-4]\n",
    "#         print \"Extracting subjects: \", P1_SID, P2_SID\n",
    "\n",
    "        # Load EDA files (fields are strings)\n",
    "        P1_L_data = np.loadtxt('./../Experiment/EDA/S' + P1_SID + '_L.csv', delimiter=\",\", skiprows=8, dtype=str)\n",
    "        P1_R_data = np.loadtxt('./../Experiment/EDA/S' + P1_SID + '_R.csv', delimiter=\",\", skiprows=8, dtype=str)\n",
    "        P2_L_data = np.loadtxt('./../Experiment/EDA/S' + P2_SID + '_L.csv', delimiter=\",\", skiprows=8, dtype=str)\n",
    "        P2_R_data = np.loadtxt('./../Experiment/EDA/S' + P2_SID + '_R.csv', delimiter=\",\", skiprows=8, dtype=str)\n",
    "\n",
    "        # EDA values are no longer strings, but times are\n",
    "        P1_L_times = P1_L_data[:,0]\n",
    "        P1_L_EDA = P1_L_data[:,6].astype(np.float32)\n",
    "\n",
    "        P1_R_times = P1_R_data[:,0]\n",
    "        P1_R_EDA = P1_R_data[:,6].astype(np.float32)\n",
    "\n",
    "        P2_L_times = P2_L_data[:,0]\n",
    "        P2_L_EDA = P2_L_data[:,6].astype(np.float32)\n",
    "\n",
    "        P2_R_times = P2_R_data[:,0]\n",
    "        P2_R_EDA = P2_R_data[:,6].astype(np.float32)\n",
    "\n",
    "        # Calculate EDA baselines - means\n",
    "    #     P1_L_baseline = np.mean([EDA for t,EDA in zip(P1_L_times,P1_L_EDA) \n",
    "    #                         if (baseline_epochs[P1_SID][0] <= t) and (t <= baseline_epochs[P1_SID][1]) ])\n",
    "    #     P1_R_baseline = np.mean([EDA for t,EDA in zip(P1_R_times,P1_R_EDA) \n",
    "    #                         if (baseline_epochs[P1_SID][0] <= t) and (t <= baseline_epochs[P1_SID][1]) ])\n",
    "    #     P2_L_baseline = np.mean([EDA for t,EDA in zip(P2_L_times,P2_L_EDA) \n",
    "    #                         if (baseline_epochs[P2_SID][0] <= t) and (t <= baseline_epochs[P2_SID][1]) ])\n",
    "    #     P2_R_baseline = np.mean([EDA for t,EDA in zip(P2_R_times,P2_R_EDA) \n",
    "    #                         if (baseline_epochs[P2_SID][0] <= t) and (t <= baseline_epochs[P2_SID][1]) ])\n",
    "\n",
    "        # Filter\n",
    "        if apply_filter:\n",
    "            f_P1_L_EDA = filt(P1_L_EDA)\n",
    "            f_P1_R_EDA = filt(P1_R_EDA)\n",
    "            f_P2_L_EDA = filt(P2_L_EDA)\n",
    "            f_P2_R_EDA = filt(P2_R_EDA)\n",
    "        else:\n",
    "            f_P1_L_EDA = P1_L_EDA\n",
    "            f_P1_R_EDA = P1_R_EDA\n",
    "            f_P2_L_EDA = P2_L_EDA\n",
    "            f_P2_R_EDA = P2_R_EDA\n",
    "\n",
    "    #     if norm_to_baseline:\n",
    "    #         # Normalize per subject (i.e. standardize) - this global normalisation did not seem to be better than unit normalisation\n",
    "    #         f_P1_L_EDA = normalize_to_baseline(f_P1_L_EDA, P1_L_baseline)\n",
    "    #         f_P1_R_EDA = normalize_to_baseline(f_P1_R_EDA, P1_R_baseline)\n",
    "    #         f_P2_L_EDA = normalize_to_baseline(f_P2_L_EDA, P2_L_baseline)\n",
    "    #         f_P2_R_EDA = normalize_to_baseline(f_P2_R_EDA, P2_R_baseline)\n",
    "\n",
    "        # Iterate over annotated events for this game\n",
    "        # Event files have structure: \n",
    "        # Event timestamp \n",
    "        #     - system time of the event determined from video recording.\n",
    "        # Event type \n",
    "        #     - D=discarding a card, S=being suspicious (calling \"Cheat\"), EOG=end of game\n",
    "        # P01 \n",
    "        #     - the suit (S=spades/C=clubs/H=hearts/D=diamonds) played by player 1 if event type is D. (if it is not P01's turn then '-'). If event type is S, then 'CH' means that P01 called \"Cheat\". \n",
    "        #     - analogously for P02\n",
    "        # True suit\n",
    "        #     - true suit (S=spades/C=clubs/H=hearts/D=diamonds) claimed by a player\n",
    "        #       (constant for one pile, until \"Cheat\" was called)\n",
    "\n",
    "        valid_epoch = False\n",
    "        events_data = np.loadtxt(game_events_file_name, delimiter=\",\", skiprows=1, dtype=str)\n",
    "        for i, event in enumerate(events_data):\n",
    "\n",
    "            event_type = event[1]\n",
    "\n",
    "            # After end of game skip the following epoch\n",
    "            if event_type == 'EOG':\n",
    "                valid_epoch = False\n",
    "\n",
    "            else:\n",
    "                # Check and correct (if needed) timestamp format\n",
    "                if len(event[0]) == 8 and event[0][2] == ':' and event[0][5] == ':':\n",
    "                    events_data[i][0] = event[0] + '.000' # system time as string\n",
    "                elif len(event[0]) == 12 and event[0][2] == ':' and event[0][5] == ':' and event[0][8] == '.':\n",
    "                    pass\n",
    "                else:\n",
    "                    print \"Timestamp error \", event\n",
    "\n",
    "                event_timestamp = events_data[i][0]\n",
    "                event_P1_label = event[2]\n",
    "                event_P2_label = event[3]        \n",
    "                true_suit = event[4]\n",
    "                if true_suit == '':\n",
    "                    print \"True suit error \", event\n",
    "\n",
    "                if event_type == 'D':\n",
    "\n",
    "                    if valid_epoch:\n",
    "\n",
    "                        if event_P1_label != '': # P1 discarded a card\n",
    "\n",
    "                            feature_vector = [P1_SID]\n",
    "                            epoch_start = events_data[i-1][0]\n",
    "                            epoch_end = event_timestamp\n",
    "                            epoch_start, epoch_end = delay_epoch(epoch_start, epoch_end, epoch_delay, P1_SID)\n",
    "\n",
    "                            data_L = [EDA for t,EDA in zip(P1_L_times,f_P1_L_EDA) \n",
    "                                      if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "                            data_R = [EDA for t,EDA in zip(P1_R_times,f_P1_R_EDA) \n",
    "                                      if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "\n",
    "                            # Normalize\n",
    "                            if znormalize:\n",
    "                                data_L = znorm(data_L)\n",
    "                                data_R = znorm(data_R)\n",
    "                            elif unitnormalize:\n",
    "                                data_L = unitnorm(data_L)\n",
    "                                data_R = unitnorm(data_R)\n",
    "\n",
    "                            # Extract features for P1\n",
    "                            retL, fL = extract_features(data_L)\n",
    "    #                         if not retL:\n",
    "    #                             print \"... skipping left-hand  DECEPT features\", P1_SID\n",
    "                            retR, fR = extract_features(data_R)\n",
    "    #                         if not retR:\n",
    "    #                             print \"... skipping right-hand DECEPT features\", P1_SID\n",
    "                            keepSample = retL and retR\n",
    "                            feature_vector.extend(fL)\n",
    "                            feature_vector.extend(fR)\n",
    "\n",
    "                            if event_P1_label == true_suit:\n",
    "                                # P1 said truth\n",
    "                                feature_vector.append(deception_classes[1])\n",
    "                                feature_vector.append(1)\n",
    "                            else:\n",
    "                                # P1 lied\n",
    "                                feature_vector.append(deception_classes[0])\n",
    "                                feature_vector.append(0)\n",
    "\n",
    "                            # Skip subject 05 for deception detection\n",
    "                            if P1_SID != '05' and keepSample:\n",
    "                                features_deception.append(feature_vector)\n",
    "\n",
    "                            ############################# Record trust\n",
    "                            feature_vector = [P1_SID]\n",
    "                            epoch_start = events_data[i-1][0]\n",
    "                            epoch_end = event_timestamp\n",
    "                            epoch_start, epoch_end = delay_trust_epoch(epoch_start, epoch_end, epoch_delay, P1_SID)\n",
    "\n",
    "                            data_L = [EDA for t,EDA in zip(P1_L_times,f_P1_L_EDA) \n",
    "                                if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "                            data_R = [EDA for t,EDA in zip(P1_R_times,f_P1_R_EDA) \n",
    "                                if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "\n",
    "                            # Normalize\n",
    "                            if znormalize:\n",
    "                                data_L = znorm(data_L)\n",
    "                                data_R = znorm(data_R)\n",
    "                            elif unitnormalize:\n",
    "                                data_L = unitnorm(data_L)\n",
    "                                data_R = unitnorm(data_R)\n",
    "\n",
    "                            # Extract features\n",
    "                            retL, fL = extract_features(data_L)\n",
    "    #                         if not retL:\n",
    "    #                             print \"... skipping left-hand  TRUST features\", P1_SID\n",
    "                            retR, fR = extract_features(data_R)\n",
    "    #                         if not retR:\n",
    "    #                             print \"... skipping right-hand TRUST features\", P1_SID\n",
    "\n",
    "                            if retL and retR: # keepSample ?\n",
    "                                feature_vector.extend(fL)\n",
    "                                feature_vector.extend(fR)\n",
    "                                feature_vector.append(suspicion_classes[1])\n",
    "                                feature_vector.append(1)\n",
    "                                features_suspicion.append(feature_vector)\n",
    "\n",
    "                        elif event_P2_label != '': # P2 discarded a card\n",
    "\n",
    "                            feature_vector = [P2_SID]\n",
    "                            epoch_start = events_data[i-1][0]\n",
    "                            epoch_end = event_timestamp\n",
    "                            epoch_start, epoch_end = delay_epoch(epoch_start, epoch_end, epoch_delay, P2_SID)\n",
    "\n",
    "                            data_L = [EDA for t,EDA in zip(P2_L_times,f_P2_L_EDA) \n",
    "                                      if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "                            data_R = [EDA for t,EDA in zip(P2_R_times,f_P2_R_EDA) \n",
    "                                      if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "\n",
    "                            # Normalize\n",
    "                            if znormalize:\n",
    "                                data_L = znorm(data_L)\n",
    "                                data_R = znorm(data_R)\n",
    "                            elif unitnormalize:\n",
    "                                data_L = unitnorm(data_L)\n",
    "                                data_R = unitnorm(data_R)\n",
    "\n",
    "                            # Extract features for P2\n",
    "                            retL, fL = extract_features(data_L)\n",
    "    #                         if not retL:\n",
    "    #                             print \"... skipping left-hand  DECEPT features\", P2_SID\n",
    "                            retR, fR = extract_features(data_R)\n",
    "    #                         if not retR:\n",
    "    #                             print \"... skipping right-hand DECEPT features\", P2_SID\n",
    "                            keepSample = retL and retR\n",
    "                            feature_vector.extend(fL)\n",
    "                            feature_vector.extend(fR)\n",
    "\n",
    "                            if event_P2_label == true_suit:\n",
    "                                # P2 said truth\n",
    "                                feature_vector.append(deception_classes[1])\n",
    "                                feature_vector.append(1)\n",
    "                            else:\n",
    "                                # P2 lied     \n",
    "                                feature_vector.append(deception_classes[0])\n",
    "                                feature_vector.append(0)\n",
    "\n",
    "                            if keepSample:\n",
    "                                features_deception.append(feature_vector)\n",
    "\n",
    "                            ############################# Record trust\n",
    "                            feature_vector = [P2_SID]\n",
    "                            epoch_start = events_data[i-1][0]\n",
    "                            epoch_end = event_timestamp\n",
    "                            epoch_start, epoch_end = delay_trust_epoch(epoch_start, epoch_end, epoch_delay, P2_SID)\n",
    "\n",
    "                            data_L = [EDA for t,EDA in zip(P2_L_times,f_P2_L_EDA) \n",
    "                                      if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "                            data_R = [EDA for t,EDA in zip(P2_R_times,f_P2_R_EDA) \n",
    "                                      if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "\n",
    "                            # Normalize\n",
    "                            if znormalize:\n",
    "                                data_L = znorm(data_L)\n",
    "                                data_R = znorm(data_R)\n",
    "                            elif unitnormalize:\n",
    "                                data_L = unitnorm(data_L)\n",
    "                                data_R = unitnorm(data_R)\n",
    "\n",
    "                            # Extract features\n",
    "                            retL, fL = extract_features(data_L)\n",
    "    #                         if not retL:\n",
    "    #                             print \"... skipping left-hand  TRUST features\", P2_SID\n",
    "                            retR, fR = extract_features(data_R)\n",
    "    #                         if not retR:\n",
    "    #                             print \"... skipping right-hand TRUST features\", P2_SID\n",
    "\n",
    "                            if retL and retR: # keepSample ?\n",
    "                                feature_vector.extend(fL)\n",
    "                                feature_vector.extend(fR)\n",
    "                                feature_vector.append(suspicion_classes[1])\n",
    "                                feature_vector.append(1)\n",
    "                                features_suspicion.append(feature_vector)\n",
    "                        else:\n",
    "                            print \"Event D \", event, \" not labeled\"\n",
    "\n",
    "                    valid_epoch = True\n",
    "\n",
    "                elif event_type == 'S':\n",
    "                    numS += 1\n",
    "                    valid_epoch = False\n",
    "                    if event_P1_label == 'CH': # P1 said cheat\n",
    "\n",
    "                        feature_vector = [P1_SID]\n",
    "                        epoch_start = events_data[i-1][0]\n",
    "                        epoch_end = event_timestamp\n",
    "                        epoch_start, epoch_end = delay_susp_epoch(epoch_start, epoch_end, epoch_delay, P1_SID)\n",
    "\n",
    "                        data_L = [EDA for t,EDA in zip(P1_L_times,f_P1_L_EDA) \n",
    "                                  if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "                        data_R = [EDA for t,EDA in zip(P1_R_times,f_P1_R_EDA) \n",
    "                                  if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "\n",
    "                        # Normalize\n",
    "                        if znormalize:\n",
    "                            data_L = znorm(data_L)\n",
    "                            data_R = znorm(data_R)\n",
    "                        elif unitnormalize:\n",
    "                            data_L = unitnorm(data_L)\n",
    "                            data_R = unitnorm(data_R)\n",
    "\n",
    "                        # Extract features\n",
    "                        retL, fL = extract_features(data_L)\n",
    "    #                     if not retL:\n",
    "    #                         print \"... skipping left-hand  SUSP features\", P1_SID\n",
    "                        retR, fR = extract_features(data_R)\n",
    "    #                     if not retR:\n",
    "    #                         print \"... skipping right-hand SUSP features\", P1_SID\n",
    "\n",
    "                        if retL and retR: # keepSample ?\n",
    "                            feature_vector.extend(fL)\n",
    "                            feature_vector.extend(fR)\n",
    "                            feature_vector.append(suspicion_classes[0])\n",
    "                            feature_vector.append(0)\n",
    "                            features_suspicion.append(feature_vector)\n",
    "\n",
    "                    elif event_P2_label == 'CH': # P2 said cheat\n",
    "\n",
    "                        feature_vector = [P2_SID]\n",
    "                        epoch_start = events_data[i-1][0]\n",
    "                        epoch_end = event_timestamp\n",
    "                        epoch_start, epoch_end = delay_susp_epoch(epoch_start, epoch_end, epoch_delay, P2_SID)\n",
    "\n",
    "                        data_L = [EDA for t,EDA in zip(P2_L_times,f_P2_L_EDA) \n",
    "                                  if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "                        data_R = [EDA for t,EDA in zip(P2_R_times,f_P2_R_EDA) \n",
    "                                  if (epoch_start <= t) and (t <= epoch_end) ]\n",
    "\n",
    "                        # Normalize\n",
    "                        if znormalize:\n",
    "                            data_L = znorm(data_L)\n",
    "                            data_R = znorm(data_R)\n",
    "                        elif unitnormalize:\n",
    "                            data_L = unitnorm(data_L)\n",
    "                            data_R = unitnorm(data_R)\n",
    "\n",
    "                        # Extract features\n",
    "                        retL, fL = extract_features(data_L)\n",
    "    #                     if not retL:\n",
    "    #                         print \"... skipping left-hand  SUSP features\", P2_SID\n",
    "                        retR, fR = extract_features(data_R)\n",
    "    #                     if not retR:\n",
    "    #                         print \"... skipping right-hand SUSP features\", P2_SID\n",
    "\n",
    "                        if retL and retR: # keepSample ?\n",
    "                            feature_vector.extend(fL)\n",
    "                            feature_vector.extend(fR)\n",
    "                            feature_vector.append(suspicion_classes[0])\n",
    "                            feature_vector.append(0)\n",
    "                            features_suspicion.append(feature_vector)\n",
    "                    else:\n",
    "                        print \"Event S \", event, \" not labeled\"\n",
    "\n",
    "                else:\n",
    "                    print \"Event type error in: \", game_events_file_name, \"; \", event\n",
    "\n",
    "    if feature_type == 'deception':\n",
    "        np.savetxt('./../Experiment/ExtractedFeatures/features_deception_u_' + file_ID + '.csv', \n",
    "                   features_deception, delimiter=',', fmt='%s')\n",
    "#         return np.array(features_deception)\n",
    "    else:\n",
    "        np.savetxt('./../Experiment/ExtractedFeatures/features_suspicion_u_' + file_ID + '.csv', \n",
    "                   features_suspicion, delimiter=',', fmt='%s')\n",
    "#         return np.array(features_suspicion)\n",
    "\n",
    "# Save extracted features: Subject ID | Left-hand features | Right-hand features | Label\n",
    "# np.savetxt('./../Experiment/ExtractedFeatures/features_deception.csv', features_deception, delimiter=',', fmt='%s')\n",
    "# np.savetxt('./../Experiment/ExtractedFeatures/features_suspicion.csv', features_suspicion, delimiter=',', fmt='%s')\n",
    "# num_truths = len([1 for row in features_deception if row[-1] == 1])\n",
    "# num_decept = len(features_deception) - num_truths\n",
    "# num_trusts = len([1 for row in features_suspicion if row[-1] == 1])\n",
    "# num_susp = len(features_suspicion) - num_trusts\n",
    "# print \"Number of examples for deception detection: \\t\", len(features_deception), \"\\n\\t shape \", np.shape(features_deception)\n",
    "# print \"\\t #truths\", num_truths, \"\\t #deceptions\", num_decept\n",
    "# print \"Number of examples for suspicion detection: \\t\", len(features_suspicion), \"\\n\\t shape \", np.shape(features_suspicion)\n",
    "# print \"\\t #trusts\", num_trusts, \"\\t #suspicions\", num_susp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janciovec/.local/lib/python2.7/site-packages/ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 \t0.5 : \t65.2227828503\n",
      "1.0 \t1.0 : \t69.6087179184\n",
      "1.0 \t1.5 : \t72.063117981\n",
      "1.0 \t2.0 : \t71.4052948952\n",
      "1.0 \t2.5 : \t70.8195228577\n",
      "1.0 \t3.0 : \t72.379253149\n",
      "1.0 \t3.5 : \t67.3871240616\n",
      "1.0 \t4.0 : \t68.0320029259\n",
      "1.0 \t4.5 : \t66.4927821159\n",
      "1.5 \t0.5 : \t66.4144070148\n",
      "1.5 \t1.0 : \t66.7719800472\n",
      "1.5 \t1.5 : \t66.0265967846\n",
      "1.5 \t2.0 : \t65.0863518715\n",
      "1.5 \t2.5 : \t65.0311188698\n",
      "1.5 \t3.0 : \t64.6708040237\n",
      "1.5 \t3.5 : \t63.8825669289\n",
      "1.5 \t4.0 : \t66.0186941624\n",
      "1.5 \t4.5 : \t64.6015100479\n",
      "2.0 \t0.5 : \t63.6988139153\n",
      "2.0 \t1.0 : \t64.7224879265\n",
      "2.0 \t1.5 : \t63.7610528469\n",
      "2.0 \t2.0 : \t65.6811199188\n",
      "2.0 \t2.5 : \t65.9122240543\n",
      "2.0 \t3.0 : \t63.8375411034\n",
      "2.0 \t3.5 : \t63.4607388973\n",
      "2.0 \t4.0 : \t65.1350970268\n",
      "2.0 \t4.5 : \t65.1130948067\n",
      "2.5 \t0.5 : \t64.0043811798\n",
      "2.5 \t1.0 : \t70.2871229649\n",
      "2.5 \t1.5 : \t70.4276850224\n",
      "2.5 \t2.0 : \t72.0877010822\n",
      "2.5 \t2.5 : \t72.1555588245\n",
      "2.5 \t3.0 : \t70.364109993\n",
      "2.5 \t3.5 : \t66.8904559612\n",
      "2.5 \t4.0 : \t66.477380991\n",
      "2.5 \t4.5 : \t66.3604719639\n",
      "3.0 \t0.5 : \t66.6896760464\n",
      "3.0 \t1.0 : \t66.7817511559\n",
      "3.0 \t1.5 : \t66.5652749538\n",
      "3.0 \t2.0 : \t64.8900060654\n",
      "3.0 \t2.5 : \t65.0542850494\n",
      "3.0 \t3.0 : \t65.2548899651\n",
      "3.0 \t3.5 : \t65.4401659966\n",
      "3.0 \t4.0 : \t65.5140330791\n",
      "3.0 \t4.5 : \t64.2848520279\n",
      "3.5 \t0.5 : \t64.6468298435\n",
      "3.5 \t1.0 : \t69.4710900784\n",
      "3.5 \t1.5 : \t72.5996580124\n",
      "3.5 \t2.0 : \t70.7022490501\n",
      "3.5 \t2.5 : \t70.3574712276\n",
      "3.5 \t3.0 : \t71.6424069405\n",
      "3.5 \t3.5 : \t71.7014079094\n",
      "3.5 \t4.0 : \t71.8118169308\n",
      "3.5 \t4.5 : \t72.8910138607\n",
      "4.0 \t0.5 : \t68.7575581074\n",
      "4.0 \t1.0 : \t67.8826138973\n",
      "4.0 \t1.5 : \t67.1891129017\n",
      "4.0 \t2.0 : \t66.6009259224\n",
      "4.0 \t2.5 : \t67.2601809502\n",
      "4.0 \t3.0 : \t67.7861220837\n",
      "4.0 \t3.5 : \t67.2258110046\n",
      "4.0 \t4.0 : \t69.0108449459\n",
      "4.0 \t4.5 : \t67.3519749641\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# Generate DECEPTION feature files with filenames of format: \n",
    "# features_{feature_type}_u_{epoch_delay}_{max_epoch_len}.csv\n",
    "# u means unit normalization\n",
    "# epoch_delay and max_epoch_len are indices of arrays:\n",
    "# eds = np.linspace(1.,4.,7) # Epoch delay ----- delta parameter\n",
    "# mels = np.linspace(0.5,4.5,9) # Max deception epoch length ----- tau parameter\n",
    "#######################################################################\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Skip subject 05 for deception detection only, not for suspicion detection\n",
    "eds = np.linspace(1.,4.,7) # Epoch delay\n",
    "mels = np.linspace(0.5,4.5,9) # Max epoch length\n",
    "feature_type = 'deception'\n",
    "\n",
    "# Over all settings of parameters\n",
    "# for ed, mel, in list(itertools.product(eds, mels)):\n",
    "for i, ed in enumerate(eds):\n",
    "    for j, mel in enumerate(mels):\n",
    "        t = time.time()\n",
    "        extract_features(feature_type, ed, mel, None, str(i)+'_'+str(j))\n",
    "        print ed, \"\\t\", mel, \": \\t\", time.time()-t\n",
    "        # cca 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janciovec/.local/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 \t0.5 : \t206.130706072\n",
      "1.0 \t1.0 : \t205.813843966\n",
      "1.0 \t1.5 : \t74.3898139\n",
      "1.0 \t2.0 : \t73.1668508053\n",
      "1.0 \t2.5 : \t70.3487589359\n",
      "1.0 \t3.0 : \t71.9408020973\n",
      "1.0 \t3.5 : \t72.2675490379\n",
      "1.0 \t4.0 : \t69.6804871559\n",
      "1.0 \t4.5 : \t70.8273730278\n",
      "1.5 \t0.5 : \t70.1733720303\n",
      "1.5 \t1.0 : \t68.8723680973\n",
      "1.5 \t1.5 : \t68.5874090195\n",
      "1.5 \t2.0 : \t69.3945481777\n",
      "1.5 \t2.5 : \t68.7767131329\n",
      "1.5 \t3.0 : \t70.7609689236\n",
      "1.5 \t3.5 : \t70.6522169113\n",
      "1.5 \t4.0 : \t69.4481389523\n",
      "1.5 \t4.5 : \t69.8093512058\n",
      "2.0 \t0.5 : \t67.0920939445\n",
      "2.0 \t1.0 : \t69.3489770889\n",
      "2.0 \t1.5 : \t67.8809530735\n",
      "2.0 \t2.0 : \t69.9358229637\n",
      "2.0 \t2.5 : \t71.4835641384\n",
      "2.0 \t3.0 : \t77.4224867821\n",
      "2.0 \t3.5 : \t80.3053629398\n",
      "2.0 \t4.0 : \t72.8475837708\n",
      "2.0 \t4.5 : \t73.1227450371\n",
      "2.5 \t0.5 : \t78.8753418922\n",
      "2.5 \t1.0 : \t85.073184967\n",
      "2.5 \t1.5 : \t186.41759491\n",
      "2.5 \t2.0 : \t218.287860155\n",
      "2.5 \t2.5 : \t231.606835127\n",
      "2.5 \t3.0 : \t218.634891033\n",
      "2.5 \t3.5 : \t205.687391996\n",
      "2.5 \t4.0 : \t207.316909075\n",
      "2.5 \t4.5 : \t180.580295801\n",
      "3.0 \t0.5 : \t76.1366438866\n",
      "3.0 \t1.0 : \t77.6508979797\n",
      "3.0 \t1.5 : \t74.6916880608\n",
      "3.0 \t2.0 : \t75.906801939\n",
      "3.0 \t2.5 : \t73.8394091129\n",
      "3.0 \t3.0 : \t75.195045948\n",
      "3.0 \t3.5 : \t73.2580800056\n",
      "3.0 \t4.0 : \t84.3738751411\n",
      "3.0 \t4.5 : \t79.30626297\n",
      "3.5 \t0.5 : \t76.2395119667\n",
      "3.5 \t1.0 : \t79.7704620361\n",
      "3.5 \t1.5 : \t80.3178789616\n",
      "3.5 \t2.0 : \t82.6152939796\n",
      "3.5 \t2.5 : \t82.1231348515\n",
      "3.5 \t3.0 : \t78.574311018\n",
      "3.5 \t3.5 : \t79.4263060093\n",
      "3.5 \t4.0 : \t73.1935491562\n",
      "3.5 \t4.5 : \t77.5779590607\n",
      "4.0 \t0.5 : \t83.2101781368\n",
      "4.0 \t1.0 : \t79.9304919243\n",
      "4.0 \t1.5 : \t76.6462709904\n",
      "4.0 \t2.0 : \t76.1497039795\n",
      "4.0 \t2.5 : \t79.6406190395\n",
      "4.0 \t3.0 : \t79.3280689716\n",
      "4.0 \t3.5 : \t82.4419279099\n",
      "4.0 \t4.0 : \t80.187525034\n",
      "4.0 \t4.5 : \t77.2217059135\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Generate SUSPICION feature files with filenames of format: \n",
    "# features_{feature_type}_u_{epoch_delay}_{max_epoch_len}.csv\n",
    "# u means unit normalization\n",
    "# epoch_delay and max_epoch_len are indices of arrays:\n",
    "# eds = np.linspace(1.,4.,7) # Epoch delay ----- delta parameter\n",
    "# msels = np.linspace(0.5,4.5,9) # maximum suspicion epoch length - tau parameter\n",
    "#######################################################################\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# FOR OPTIMIZING msel\n",
    "\n",
    "# Skip subject 05 for deception detection only, not for suspicion detection\n",
    "eds = np.linspace(1.,4.,7) # Epoch delay\n",
    "msels = np.linspace(0.5,4.5,9) # mean suspicion length\n",
    "feature_type = 'suspicion'\n",
    "mel=1. # arbitrary for suspicion features extraction\n",
    "    \n",
    "# Over all settings of parameters\n",
    "for i, ed in enumerate(eds):\n",
    "    for j, msel in enumerate(msels):\n",
    "        t = time.time()\n",
    "        extract_features(feature_type, ed, mel, msel, str(i)+'_'+str(j))\n",
    "        print ed, \"\\t\", msel, \": \\t\", time.time()-t\n",
    "        # cca 1 min\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
